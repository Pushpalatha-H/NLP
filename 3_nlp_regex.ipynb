{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7eXHoEA79szbwbV1vkoOt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pushpalatha-H/NLP/blob/main/3_nlp_regex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regex in nlp is matching pattern in text and retreviewing key information out of it. pattern matching for emails mobile numbers, etc"
      ],
      "metadata": {
        "id": "u4l6_XfPMKUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re              #regular expression allows to do pattern matching."
      ],
      "metadata": {
        "id": "Sp7UiJd-Nm7h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "in regex101 website for singledigit \\d, \\d\\d for 2, for continous 10 digit \\d{10}"
      ],
      "metadata": {
        "id": "HL6lCdfNZkWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat1 = 'codebasics: you ask lot of questions 1234567891, abc@xyz.com'\n",
        "chat2 = 'codebasics: here it is: (123)-567-8912, abc_82@xyz.com'\n",
        "chat3 = 'codebasics: yes, phone: 1235678912 email: abc@xyz.com'"
      ],
      "metadata": {
        "id": "YDqkKV37Zl0h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern ='\\d{10}'       #to find continuous 0 digit\n",
        "matches = re.findall(pattern, chat1)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWyt8L3eZsNh",
        "outputId": "a4b13721-c604-493f-a02a-c34292ec55bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1234567891']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it will show even it has 2 set of numbers in same sentence"
      ],
      "metadata": {
        "id": "gUtJ9dzhaF-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat4 = 'codebasics: here are numbers: 1234567249, 1345678928'\n",
        "pattern = '\\d{10}'\n",
        "matches = re.findall(pattern, chat4)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or8wHampZ66u",
        "outputId": "20b30e68-6999-4fd6-a005-0f6ff44fda0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1234567249', '1345678928']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to match chat2 it has (123)-567-8912 in regex we use \\(\\d{3}\\)-\\d{3}-\\d{4} , to nullify the braces we use \\ along with that , if we use only braces() it will select all the thing. But to select only that (123) num we use \\(\\)"
      ],
      "metadata": {
        "id": "cRLlWtZecSZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = '\\(\\d{3}\\)-\\d{3}-\\d{4}'       # add \\near braces to get only 3\n",
        "matches = re.findall(pattern, chat2)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPGQECMRdNmv",
        "outputId": "845462a0-26b4-4c26-8450-2cf846ac4b05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(123)-567-8912']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To select both the numbers (123)-567-8912 format and 1234567891  we should use or in between that"
      ],
      "metadata": {
        "id": "tU_V2q6DVzb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = '/\\d{10}|\\(\\d{3}\\)-\\d{3}-\\d{4}'    # 1st apttern for continous 10 digit and second is for other format\n",
        "\n",
        "matches = re.findall(pattern, chat2)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL5AzGd4SqO3",
        "outputId": "f2be8fde-9b37-4e4f-edc9-9866854c1150"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(123)-567-8912']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To match the email that is in the format xxx@xxx.com\n"
      ],
      "metadata": {
        "id": "ALC04FXVYrtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#[a-z] for single character , so add * to select all from [a-z]\n",
        "#[a-z0-9A-Z_]*@[a-z0-9A-Z_]*\\.[a-z]   # to select small alphabet, capital, numbers and underscore, * is to select all\n",
        "\n",
        "pattern = '[a-z0-9A-Z_]*@[a-z0-9A-Z_]*\\.[a-z]*'\n",
        "\n",
        "matches = re.findall(pattern, chat2)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lt_WsQTZdx9",
        "outputId": "17860498-bfc0-436b-fc95-241b6052d871"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abc_82@xyz.com']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#or\n",
        "pattern = '[a-z0-9A-Z_]*@[a-z0-9A-Z_]*\\.[a-z]*'\n",
        "\n",
        "matches = re.findall(pattern, chat3)\n",
        "emails = matches[0]\n",
        "emails"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kWyx8JS6ah2E",
        "outputId": "8180a982-6f72-43de-be8f-99d0b14f8a4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abc@xyz.com'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To import order number from the chats"
      ],
      "metadata": {
        "id": "dTyLW6I2wGay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat1='codebasics: Hello, I am having an issue with my order # 412889922'\n",
        "chat2='codebasics: I have a problem with my order number 412889912'\n",
        "chat3='codebasics: My order 412889913 is having an issue, I was charged 300$ when online it says 280$'"
      ],
      "metadata": {
        "id": "4-8iSaI4wMig"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first we should find order, so type order\n",
        "# second we should get all the elements which are not in digits. i.e, anything b/w word order and numbers present\n",
        "# so [^\\d] this is choose anything except digits , it will select single digit, to select all add *, so, [^\\d]*\n",
        "# third choose all the digits \\d* , we only need order number so add braces for that (\\d*)\n",
        "# order[^\\d](\\d*)"
      ],
      "metadata": {
        "id": "jgkvcx9dxpOW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "pattern = 'order[^\\d]*(\\d*)'\n",
        "matches = re.findall(pattern, chat3)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSD0mmtQxOpc",
        "outputId": "779db45a-6dbd-4843-da94-83fed4a78dc4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['412889913']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting information from the text"
      ],
      "metadata": {
        "id": "f6I6gJbF0HRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text='''\n",
        "Born\tElon Reeve Musk\n",
        "June 28, 1971 (age 50)\n",
        "Pretoria, Transvaal, South Africa\n",
        "Citizenship\n",
        "South Africa (1971–present)\n",
        "Canada (1971–present)\n",
        "United States (2002–present)\n",
        "Education\tUniversity of Pennsylvania (BS, BA)\n",
        "Title\n",
        "Founder, CEO and Chief Engineer of SpaceX\n",
        "CEO and product architect of Tesla, Inc.\n",
        "Founder of The Boring Company and X.com (now part of PayPal)\n",
        "Co-founder of Neuralink, OpenAI, and Zip2\n",
        "Spouse(s)\n",
        "Justine Wilson\n",
        "​\n",
        "​(m. 2000; div. 2008)​\n",
        "Talulah Riley\n",
        "​\n",
        "​(m. 2010; div. 2012)​\n",
        "​\n",
        "​(m. 2013; div. 2016)\n",
        "'''"
      ],
      "metadata": {
        "id": "_IsG6yVF0NSu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### to get age"
      ],
      "metadata": {
        "id": "_2WPp-babpwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to get age\n",
        "pattern = 'age (\\d+)'    # + means one or more digit, * means zero or more digit, ( ) to get only age as o/p\n",
        "\n",
        "matches = re.findall(pattern, text)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaG9Zbdt0ZIe",
        "outputId": "aec04e9e-aace-42a9-c483-d4037d9a511c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['50']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to get name which ispresent after Born\n",
        "#Born(.*)\\n  ,  # . means any character, * means zero or more character, () to get only name, \\n means end of the line"
      ],
      "metadata": {
        "id": "p-7TxNnx1TEN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get name from text"
      ],
      "metadata": {
        "id": "PdfSL7-dbvvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to get name from text which is after Born\n",
        "pattern = 'Born(.*)\\n'\n",
        "\n",
        "matches = re.findall(pattern, text)\n",
        "matches[0].strip()  # strip to remove the white spaces \\t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MFI3cw333giZ",
        "outputId": "074047f8-9235-424a-a380-545a63764307"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Elon Reeve Musk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get date of birth which is below the Born line\n",
        "# copy paste the previous one 'Born.*\\n(.*)\\(age)'    # '.' means anything after born line, '*' means everything after born line,\n",
        "                                                      # '\\(age)'  means before age or except age"
      ],
      "metadata": {
        "id": "bCLT5_M24C52"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get date of birth"
      ],
      "metadata": {
        "id": "oDHErlTyb9Be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = 'Born.*\\n(.*)\\(age'\n",
        "\n",
        "matches = re.findall(pattern, text)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1vVPoHN5lf5",
        "outputId": "26da3ab7-fff3-4866-f4f7-9e8e0a26b9dc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['June 28, 1971 ']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to get birth place which is below the age line\n",
        "# age.*/n(.*)  # age after that , '.'anything, '*' everything, '/n' end of the line,\n",
        "# after the age line '.' anything '*' everything , () to get only that thing"
      ],
      "metadata": {
        "id": "ephRo_zF6Hhu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get born place"
      ],
      "metadata": {
        "id": "vvEiEgPDcKNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Born place\n",
        "pattern = 'age.*\\n(.*)'\n",
        "\n",
        "matches = re.findall(pattern, text)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-E3oH757vio",
        "outputId": "0555f5be-c0eb-46d9-94e6-884b3ece87ca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pretoria, Transvaal, South Africa']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pattern_match(pattern, text):\n",
        "  matches = re.findall(pattern, text)\n",
        "  if matches:\n",
        "    return matches[0]"
      ],
      "metadata": {
        "id": "VHn2NUp08Aqh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pattern_match('age.*\\n(.*)', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HbIVUxX4ZQRu",
        "outputId": "effbebbb-4a2a-4e09-de74-dbb6c63c3ffc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pretoria, Transvaal, South Africa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_personal_information(text):\n",
        "  age = get_pattern_match('age (\\d+)', text)\n",
        "  full_name = get_pattern_match('Born(.*)\\n', text)\n",
        "  dob = get_pattern_match('Born.*\\n(.*)\\(age', text)\n",
        "  birth_place = get_pattern_match('age.*\\n(.*)', text)\n",
        "  return {\n",
        "      'age' : str(age),\n",
        "      'name' : full_name.strip(),\n",
        "      'dob' : dob.strip(),\n",
        "      'birth_place' : birth_place.strip()\n",
        "  }"
      ],
      "metadata": {
        "id": "k9NXy7zRZYPJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_personal_information(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG4EDIREb7nu",
        "outputId": "541efca5-6844-42de-9f65-2352f8f43ada"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'age': '50',\n",
              " 'name': 'Elon Reeve Musk',\n",
              " 'dob': 'June 28, 1971',\n",
              " 'birth_place': 'Pretoria, Transvaal, South Africa'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pattern_match(pattern, text):\n",
        "  matches = re.findall(pattern, text)\n",
        "  if matches:\n",
        "    return matches[0]"
      ],
      "metadata": {
        "id": "gakqHLfrcFuN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pattern_match('age.*\\n(.*)', text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N6LaXvzGcqJD",
        "outputId": "d5fc2899-2504-4c35-91bf-fccc2ddd559d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pretoria, Transvaal, South Africa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Extract all twitter handles from following text. Twitter handle is the text that appears after https://twitter.com/ and is a single word. Also it contains only alpha numeric characters i.e. A-Z a-z , o to 9 and underscore _"
      ],
      "metadata": {
        "id": "hxwlKKbHgh_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "Follow our leader Elon musk on twitter here: https://twitter.com/elonmusk, more information\n",
        "on Tesla's products can be found at https://www.tesla.com/. Also here are leading influencers\n",
        "for tesla related news,\n",
        "https://twitter.com/teslarati\n",
        "https://twitter.com/dummy_tesla\n",
        "https://twitter.com/dummy_2_tesla\n",
        "'''\n",
        "pattern = 'https://twitter\\.com/([a-zA-Z0-9_]+)' # todo: type your regex here\n",
        "\n",
        "re.findall(pattern, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZjL_NLNgliO",
        "outputId": "418ff5c5-14a2-41e6-9609-1353439a313f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elonmusk', 'teslarati', 'dummy_tesla', 'dummy_2_tesla']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Extract Concentration Risk Types. It will be a text that appears after \"Concentration Risk:\", In below example, your regex should extract these two strings\n",
        "\n",
        "(1) Credit Risk\n",
        "\n",
        "(2) Supply Rish"
      ],
      "metadata": {
        "id": "nSD1OCIqmTM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "Concentration of Risk: Credit Risk\n",
        "Financial instruments that potentially subject us to a concentration of credit risk consist of cash, cash equivalents, marketable securities,\n",
        "restricted cash, accounts receivable, convertible note hedges, and interest rate swaps. Our cash balances are primarily invested in money market funds\n",
        "or on deposit at high credit quality financial institutions in the U.S. These deposits are typically in excess of insured limits. As of September 30, 2021\n",
        "and December 31, 2020, no entity represented 10% or more of our total accounts receivable balance. The risk of concentration for our convertible note\n",
        "hedges and interest rate swaps is mitigated by transacting with several highly-rated multinational banks.\n",
        "Concentration of Risk: Supply Risk\n",
        "We are dependent on our suppliers, including single source suppliers, and the inability of these suppliers to deliver necessary components of our\n",
        "products in a timely manner at prices, quality levels and volumes acceptable to us, or our inability to efficiently manage these components from these\n",
        "suppliers, could have a material adverse effect on our business, prospects, financial condition and operating results.\n",
        "'''\n",
        "pattern = 'Concentration of Risk:(.*)\\n' # todo: type your regex here\n",
        "\n",
        "re.findall(pattern, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHysswoLlhT8",
        "outputId": "517193af-edcf-477f-b70d-8e86a9e9802f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Credit Risk', ' Supply Risk']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "Tesla's gross cost of operating lease vehicles in FY2021 Q1 was $4.85 billion.\n",
        "BMW's gross cost of operating vehicles in FY2021 S1 was $8 billion.\n",
        "'''\n",
        "\n",
        "pattern = 'FY(\\d{4} [a-zA-Z0-9_]+)'\n",
        "matches = re.findall(pattern, text)\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlo0z9Gymh-f",
        "outputId": "e1beb665-39bf-4e25-e502-de2612ab8aef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2021 Q1', '2021 S1']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[4. Nlp]. There are three techniques to solve nlp problem\n",
        "1. Rule & Heuristics\n",
        "2. Machine Learning\n",
        "3. Deep Learning"
      ],
      "metadata": {
        "id": "Y_ju8EjMmTFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP Technique\n",
        "1. To classify the complaint as high, medium and low"
      ],
      "metadata": {
        "id": "w1ZkOTWtY9g9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[text]-----> [TF-IDF Vectorizer]---->[0.36, 0.67, 0.222, 0,0,0.56,...]--->[Naive Bayes Classifier]---->[High, Medium, low]   , TF-IDF Vectorizer will convert text into numbers"
      ],
      "metadata": {
        "id": "5qqFA5IVYUY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. if we have images of medical prescripton and patients record stored in cloud, here ML come into use"
      ],
      "metadata": {
        "id": "PsvpHCzxZ_RX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[image stored in cloud]----->[Apply OCR(Google Tesseract OCR)]---->[Text]--->[Doc2Vec]--->[0.36,0.67,0.299,0,0,0.56...]--->[Logistic Regression Classification]-----[Prescription, Patient Record]"
      ],
      "metadata": {
        "id": "jEdWlg7dab2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Hate speech detection by Facebook"
      ],
      "metadata": {
        "id": "HVcaTPLOcc_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "They deveoped a algorithm which predicted hate speech detection, now then can automatically delete hate speech\n",
        "\n",
        "Even linkedin has some algorithm to detect the profile is fake or not"
      ],
      "metadata": {
        "id": "imEwsz4mckT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2]. Text Similarity\n",
        "\n",
        "i. Matching resume with similar key words like using Hugging Face we can get the similarity score,\n",
        "\n",
        "ii. Resume Screener matching particular resume with job discriptions\n",
        "\n"
      ],
      "metadata": {
        "id": "Qnr1pPL6dA9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "job descrip[skills:Requried]--->[Sentence Encoder]--->[45,12,45,..]---------------->\n",
        "                                                                             [Cosine Similarity]\n",
        "\n",
        "Resume[Exploratory data analysis using pandas....]--->[Sentence Encoder]--->[41,10,7....]---------->     [Cosine similarity] 65%"
      ],
      "metadata": {
        "id": "FXOn6VS2Z5gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3].Information Extraction\n",
        "\n",
        "ex: Google keyword extraction"
      ],
      "metadata": {
        "id": "-Ca6rqfbbFiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[4]. Information Retrival\n",
        "\n",
        "ex:\n",
        "(i). Google search like salon near me it will show the relevant results according to my location and all\n",
        "\n",
        "(ii). TFIDF Score and BERT for information Retrival\n",
        "\n",
        "(iii). ChatBots\n",
        "   i. FAQ Bot which has fixed number of answers\n",
        "   ii. Flow-Based Bot i.e, connection b/w previous chat and recent chat\n",
        "   iii. Open-Ended Bot i.e, like chit chatting with friend like general conversation more like\n",
        "\n",
        "  (iv). Machine Translation\n",
        "\n",
        "  ex: Google translator\n",
        "\n",
        "(v). Language Modeling\n",
        "ex: sentance auto completing by gmail\n",
        "    i. Statistical Model\n",
        "    ii. Neural Model\n",
        "\n",
        "(V). Text Summarization\n",
        "ex: Summarizing the whole article to a single sentence\n",
        "\n",
        "\n",
        "(Vi). Topic Modeling\n",
        "\n",
        "We can use topic modelling to retrive the extract toppics out of it.\n",
        "\n",
        "(vii). Voice Assistants"
      ],
      "metadata": {
        "id": "cHLIiuW_bpMX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fv98hlfWYwm9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NLP Pipe Line ##\n",
        "\n",
        "step1 : **Data Acquisition** : To get necessary data required to solve nlp problem\n",
        "\n",
        "i. By using the data present in company from past years\n",
        "\n",
        "ii. Use a public dataset such as\n",
        "  i. Google has search engine for datasets\n",
        "\n",
        "  ii. us consultancies has lot of economic data\n",
        "\n",
        "  iii. Use webscrapping to scrape the data from internet\n",
        "  \n",
        "  iv. Product inervention, data agumentation, etc..\n",
        "\n",
        "step 2: **Text Extraction & Cleanup**\n",
        "\n",
        "i. Discard irrelevant information and creating simple version of your text data\n",
        "\n",
        "ii. spelling correction + Remove \\n\\n\n",
        "\n",
        "iii. Sentence Segmentation or Sentence tokenization (splitting the sentence)\n",
        "\n",
        "iv. word tokenization(splitting words)\n",
        "\n",
        "v. Stemming : loves -> love, eating -> eat, adjustable -> adjust\n",
        "\n",
        "vi. Lemmatization: mapping the word to its base word (ate -> eat, was -> (to)be, better -> good, meeting -> meeting)\n",
        "\n"
      ],
      "metadata": {
        "id": "QM7n9rJciK__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First three steps in NLP Pipeline\n",
        "\n",
        "[Data Acquisition]---->[Text Extraction & Cleanup]---->[Pre-processing]---> [Feature Engineering]\n",
        "|down|\n",
        "\n",
        "|up|\n",
        "\n",
        "[Monitor & Update]<----------------[Deployment]<-------------[Evaluation]<---------[Model building]\n",
        "\n",
        "we get textad o/p, should convert words to numbers coz machine learning cannot understand words.\n",
        "\n",
        "This method of extracting words into numbers is called **Feature Engineering**\n",
        "\n",
        "The method for converting words into numbers are [TF-IDF Vectorizer, One Hot Encoding, Word Embedding]\n",
        "\n",
        "**Model building**: Building a model to predict the ticket whether it is high, medium or low by using [Naive Bayes Classifier, SVM, Random Forest]\n",
        "\n"
      ],
      "metadata": {
        "id": "zIdekQO5oDQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spacy vs NLTK\n",
        "\n",
        "When building NLP application we might end up using many libraries such as Spacy, NLTK, Gensim, pytorch, Tensorflow, Hugging Face,..\n",
        "\n",
        "Spacy and NLTK is most widely used NLP libraries"
      ],
      "metadata": {
        "id": "yMj5KYdps-bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw1TM4zmkANd",
        "outputId": "47b9cabe-7ccd-4c7c-c86a-608633bfe130"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suk7K99JkL1O",
        "outputId": "5df08714-abfc-4a13-b1b8-7306326d77de"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spacy##"
      ],
      "metadata": {
        "id": "xDdwVHlD_vPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "pQWiKHQNkU8B"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")    # we are going to use english core package for this\n",
        "\n",
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")      # split paragraph into sentences then to words\n",
        "\n",
        "for sentence in doc.sents:       # sentence tokenization in spacy\n",
        "  print(sentence)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnI2jG4Qs_Gn",
        "outputId": "61ca655c-cf18-4496-9efd-63511c460b18"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Strange loves pav bhaji of mumbai.\n",
            "Hulk loves chat of delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in doc.sents:        # word tokenization\n",
        "  for word in sentence:           # By looking at the code we can say that spacy is a object oriented programme\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06y6VZHKtW7g",
        "outputId": "eb1f9417-0243-4aad-ed5f-6e86a3200b67"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "pav\n",
            "bhaji\n",
            "of\n",
            "mumbai\n",
            ".\n",
            "Hulk\n",
            "loves\n",
            "chat\n",
            "of\n",
            "delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nltk##"
      ],
      "metadata": {
        "id": "FEaMFYiK_eC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk           #nltk\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSxKuEhAwOaz",
        "outputId": "72aeaadc-76e4-435f-e4e4-93829222582c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize         #nltk is a string processing library\n",
        "\n",
        "sent_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")      # we got 3 sentences o/p here, it is not object oriented"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhwJemTjwZ9G",
        "outputId": "bcefb620-e8ad-49c8-bc61-7aef5ef34a16"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr.', 'Strange loves pav bhaji of mumbai.', 'Hulk loves chat of delhi']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4wLOP0KEWK0",
        "outputId": "91502f5b-3d05-4f2f-be24-279d60c2b79b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr',\n",
              " '.',\n",
              " 'Strange',\n",
              " 'loves',\n",
              " 'pav',\n",
              " 'bhaji',\n",
              " 'of',\n",
              " 'mumbai',\n",
              " '.',\n",
              " 'Hulk',\n",
              " 'loves',\n",
              " 'chat',\n",
              " 'of',\n",
              " 'delhi']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spacy##                                                               \n",
        "i. Spacy is Object Oriented\n",
        "\n",
        "ii. Spacy provides most efficient NLP algorithm for a given task. Hence if you care about the end result, go with Spacy.\n",
        "\n",
        "iii. Spacy is user friendly\n",
        "\n",
        "iv. Spacy is perfect for app developers\n",
        "\n",
        "v. Spacy is new library and has a very active user community\n",
        "\n",
        "##NLTK##\n",
        "i. NLTK is mainly a string processing library\n",
        "\n",
        "ii. NLTK provides access to many algorithm. If you care about specific algo and customizations go with NLTK\n",
        "\n",
        "iii. NLTK is also a userfriendly but less user friendly compared to Spacy\n",
        "\n",
        "iv. NLTK is perfect for esearchers\n",
        "\n",
        "v. NLTK is old library. User community not as active as Spacy\n"
      ],
      "metadata": {
        "id": "rQ3O56yGwmM9"
      }
    }
  ]
}